{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and export Sneaker Wizard Model\n",
    "\n",
    "This juypter notebook will be used to train and deploy our \"sneaker wizard\" model! Please refer to this notebook once you have downloaded the training images! :)\n",
    "\n",
    "\n",
    "Every notebook starts with the following three lines; they ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before lets import all the necessary packages; fastai V1 library with Pytorch and matplotlib. We'll also set the working path to our 'dataset/sneakers' directory where all our training images are stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = Path('dataset/sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('dataset/sneakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get an out of memory error. If this happens, click Kernel -> Restart, uncomment the 2nd line to use a smaller \"batch size\" and try running the notebook again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "# bs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a better understanding of our dataset from the downloaded set of training images. Here we'll use the ImageDataBunch function to create a validation set, view our data, and transform our images.\n",
    "\n",
    "We'll list out all the sneaker classes, number of classes, number of images in the training set and in the validation set. We'll also view a sample set of our images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n",
    "        ds_tfms=get_transforms(), size=299, bs=bs//2, num_workers=4).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes, data.c, len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=5, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training: Resnet101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start training our model. We will use a [convolutional neural network](http://cs231n.github.io/convolutional-networks/) to build a model which will take images as input and will output the predicted probability for each of the categories. \n",
    "\n",
    "We will train for 5 epochs (5 cycles through all our data) and save our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network resnet 101; can specify to something different\n",
    "learn2 = cnn_learner(data, models.resnet101, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what results we have got. \n",
    "\n",
    "We will first plot the model's top losses; categories that the model most confused with one another. In our case the mistakes look reasonable which is an indicator that our classifier is working correctly.\n",
    "\n",
    "Once we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes but it rarely confuses other categories. The model finds it difficult to classify some specifc categories between each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9,figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(interp.plot_top_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(interp.plot_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreezing, fine-tuning, and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.lr_find()\n",
    "learn2.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "learn2.save('stage-1-101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cycle 2, 5 epochs\n",
    "learn2.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "learn2.save('stage-2-101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training cycle 3, 8 epochs\n",
    "learn2.fit_one_cycle(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.save('stage-3-101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any of the models; in this case we chose the 3rd iteration cycle\n",
    "learn2.load('stage-3-101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model into 'export.pkl'\n",
    "learn2.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local testing using the instance\n",
    "defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(Path('test_images')/'jordan_ts_test.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predication bar chart for comparsion\n",
    "pred = learn.predict(img)\n",
    "pred_result = pred[2].sort(descending=True)\n",
    "top_3_pred_probs = pred_result[0][:3]\n",
    "# convert probs to numpy array because I just want the numbers by themselves without 'tensor'\n",
    "top_3_pred_probs = top_3_pred_probs.numpy()\n",
    "\n",
    "top_3_pred_class_idxs = pred_result[1][:3]\n",
    "\n",
    "# Convert label from 'air_jordan_3' to 'Air Jordan 3' after looking up proper index\n",
    "top_3_pred_classes = [learn.data.classes[i].replace('_', ' ').title() for i in top_3_pred_class_idxs]\n",
    "\n",
    "pred_top_3_output = list(zip(top_3_pred_classes, top_3_pred_probs))\n",
    "print(pred_top_3_output)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "df=pd.DataFrame({'allvarlist':top_3_pred_classes,'importances': top_3_pred_probs})\n",
    "df.sort_values('importances',inplace=True)\n",
    "df.plot(kind='barh',y='importances',x='allvarlist', legend=False, title='Top 3 Predicted Models');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy a Lambda application for Sneaker Wizard model\n",
    "\n",
    "Deploys a predicting application for the trained sneaker wizard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tarfile\n",
    "import PIL\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clases text for pytorch model\n",
    "save_texts(path/'models/classes.txt', data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stage-3-101 model into a format for pytorch model application\n",
    "trace_input = torch.ones(1,3,499,499).cuda()\n",
    "jit_model = torch.jit.trace(learn.model.cuda(), trace_input)\n",
    "model_file='sneaker_wiz_model_res101.pth'\n",
    "output_path = str(path/f'models/{model_file}')\n",
    "torch.jit.save(jit_model, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_file=path/'models/model.tar.gz'\n",
    "classes_file='classes.txt'\n",
    "with tarfile.open(tar_file, 'w:gz') as f:\n",
    "    f.add(path/f'models/{model_file}', arcname=model_file)\n",
    "    f.add(path/f'models/{classes_file}', arcname=classes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file(str(tar_file), 'fastai-data-bucket', 'models/modelres101.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
